{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS229: Problem Set 2\n",
    "\n",
    "## 2. Model Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood of regression model is\n",
    "$$J(\\theta)=\\frac{1}{m}\\sum_{i=1}^m{[y^{(i)}\\log{h_\\theta(x^{(i)}) + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))]}}}$$\n",
    "\n",
    "The gradient of above with respect to $\\theta_j$ and setting it to $0$, we can get\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j}&=\\sum_{i=1}^m{[y^{(i)}-h_\\theta(x^{(i)})]x_j^{(i)}} \\\\ &=0\n",
    "\\end{aligned}\n",
    "$$\n",
    "For all $\\theta$, it can be written in matrix form\n",
    "$$X(Y-h(X))=0$$\n",
    "\n",
    "Expanding the equation gives\n",
    "$$\n",
    "\\begin{equation}       %开始数学环境\n",
    "\\left[                 %左括号\n",
    "  \\begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置\n",
    "    1 & ... & 1\\\\  %第一行元素\n",
    "    x_1^1 & ... & x_n^1\\\\  %第二行元素\n",
    "     & ... & \\\\\n",
    "    x_1^m & ... & x_n^m\\\\\n",
    "  \\end{array}\n",
    "\\right]                 %右括号\n",
    "\\end{equation}(Y-h_\\theta(X))=0\n",
    "$$\n",
    "\n",
    "We only focus on the first line, there is \n",
    "$$\n",
    "\\sum_{i=1}^m[y^{(i)}-h_\\theta(x^{(i)})]=0\n",
    "$$\n",
    "So\n",
    "$$\n",
    "\\sum_{i=1}^my^{(i)} = \\sum_{i=1}^mh_\\theta(x^{(i)})\n",
    "$$\n",
    "\n",
    "Using definition of $h_\\theta$\n",
    "$$\n",
    "\\sum_{i=1}^m{1\\{y^{(i)}=1\\}} = \\sum_{i=1}^m{P(y=1|x;\\theta)}\n",
    "$$\n",
    "Finally, given $(a,b)=(0,1)$, all probilities should be between $(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good calibration is only related to probability, it is only related to the overall sample, and has nothing to do with itself, so good accuracy cannot be obtained. For example, when x is unchanged, all ys in disorderly order will have the same overall probability, but the accuracy will decrease. \n",
    "\n",
    "On the contrary, if the accuracy is high, the calibration is naturally high.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
